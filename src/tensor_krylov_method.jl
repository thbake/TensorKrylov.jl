# Aliases
const KronProd{T} = Vector{Array{T}} 
const KronMat{T} = KroneckerMatrix{T}
const LowerTriangle{T} = LowerTriangular{T, Matrix{T}} 
const FMatrices{T} = Vector{Matrix{T}} 

function mul!(result::Vector{Array{T}}, y::Vector{Array{T}}, x::ktensor) where T <: AbstractFloat

    # Compute product between elementary tensor and factor matrices of Kruskal tensor.

    n·µ¢ = ndims(x)

   for s = 1:n·µ¢

       # Result is vector of row vectors
       result[s] = transpose(y[s]) * (x.lambda' .* x.fmat[s])

   end

end

function mul!(
        result::Vector{Array{T}},
        x::Vector{Array{T}},
        A::FMatrices{T},
        Œª) where T <: AbstractFloat

    n·µ¢ = length(result)

   for s = 1:n·µ¢

       result[s] = transpose(x[s]) * (Œª' .* A[s])

   end

end

function matrix_exponential_vector!(
        factors::AbstractVector,
        A::KronMat{T},
        b::KronProd{T},
        Œ≥::T) where T<:AbstractFloat

    for s = 1:length(A)

        factors[s] = LinearAlgebra.BLAS.gemv('N' , exp(- Œ≥ * A[s]), b[s] )

    end

end

function innerprod_kronsum_tensor!(
        yX::Vector{Array{T}},
        yAx::Vector{Array{T}},
        Ax::Vector{Array{T}},
        x::ktensor,
        y::Vector{Array{T}}) where T <: AbstractFloat

    # Computes <Ax, y>‚ÇÇ, where A is a matrix (Kronecker sum) and y is a Kruskal tensor.
    mul!(yX, y, x)    # Here I already scale with Œª
    mul!(yAx, y, Ax, x.lambda)  

    mask = trues(length(Ax))

    Ax_y = 0.0

    for s = 1:length(Ax), i = 1:ncomponents(x)

        mask[s] = false

        Ax_y += maskprod(yX[mask], i) * maskprod(yAx[.!mask], i)

    end

    return Ax_y

end

function solve_compressed_system(
        H::KroneckerMatrix{T}, 
        b::Vector{Array{T}}, 
        œâ::Array{T},
        Œ±::Array{T},
        t::Int) where T <: AbstractFloat

    Œª = min_eigenvalue(H) # This might be different depending on the system

    reciprocal = inv(Œª)

    # Since we are considering a canonical decomposition the tensor rank of y‚Çú
    # is equal to 
    
    y‚Çú = ktensor(reciprocal .* œâ, [ ones(t,t) for _ in 1:length(H)] )
    
    for j = 1:t

        Œ≥ = -Œ±[j] * reciprocal

        matrix_exponential_vector!(y‚Çú.fmat, H, b, Œ≥)

    end

    return y‚Çú
end

function compute_lower_triangle!(L::LowerTriangle{T}, Œ≥::Array{T}) where T <: AbstractFloat

    # Lower triangular matrix representing the outer product of a vector with itself

    t = size(L, 1)

    for j = 1:t, i = j:t

        L[i, j] = Œ≥[i] * Œ≥[j]

    end

end

function compute_coefficients(Œõ::LowerTriangle{T}, Œ¥::Array{T}) where T <: AbstractFloat

    t = length(Œ¥)

    Œî = ones(t, t)

    # Lower triangle of outer product
    compute_lower_triangle!(Œî, Œ¥) # ‚àà ‚Ñù·µó·µó

    Œì = Œî .* Œõ

    return Œì

end

function matrix_vector(
        A::KroneckerMatrix{T},
        x::ktensor)::AbstractVector where T<:AbstractFloat

    # Compute the matrix vector products 
    #   
    #   z‚ÅΩÀ¢‚Åæ·µ¢ = A‚Çõ‚ãÖ x‚ÅΩÀ¢‚Åæ·µ¢ for s = 1,‚Ä¶,d, i = 1,‚Ä¶,t
    #
    # This is equivalent as computing the product Z‚ÅΩÀ¢‚Åæ = A‚Çõ‚ãÖX‚ÅΩÀ¢‚Åæ, where X‚ÅΩÀ¢‚Åæ
    # are the factor matrices of the CP-tensor x.

    orders = dimensions(A)
    rank   = ncomponents(x)

    # Return vector of matrices as described above
    Z = [ zeros(orders[s], rank) for s in eachindex(A) ]

    for s = 1:length(A)

        LinearAlgebra.mul!(Z[s], A[s], x.fmat[s])

    end

    return Z

end

function skipindex(index::Int, range::UnitRange{Int})

    return Iterators.filter(r -> r != index, range)

end

function maskprod(A::FMatrices{T}, i::Int, j::Int) where T <: AbstractFloat

    # Compute product of entries (i,j) of the matrices contained in A.

    return prod(getindex.(A, i, j)) 

end

function maskprod(x::Vector{Array{T}}, i::Int) where T <: AbstractFloat

    return prod(getindex.(x, i)) 

end

function efficient_matrix_vector_norm(
        x::ktensor,
        Œõ::Matrix{T},
        X_inner::FMatrices{T},
        Z::FMatrices{T}) where T <: AbstractFloat

    # Compute the squared 2-norm ||Ax||¬≤, where A ‚àà ‚Ñù·¥∫√ó·¥∫ is a Kronecker sum and
    # x ‚àà ‚Ñù·¥∫ is given as a Kruskal tensor of rank t.
    #
    # X_inner holds the inner products 
    #
    #   x·µ¢‚ÅΩÀ¢‚Åæ·µÄx‚±º‚ÅΩÀ¢‚Åæ for s = 1,‚Ä¶,d, i,j = 1,‚Ä¶,t
    #
    # And Z contains the matrices that represent the matrix vector products
    # 
    #   z‚ÅΩÀ¢‚Åæ·µ¢ = A‚Çõ‚ãÖ x‚ÅΩÀ¢‚Åæ·µ¢ for s = 1,‚Ä¶,d, i = 1,‚Ä¶,t
    #
    # A is not passed explicitly, as the precomputed inner products are given.

    d      = ndims(x)
    rank   = ncomponents(x)

    # The following contain inner products of the form 
    #
    #   z·µ¢‚ÅΩÀ¢‚Åæ·µÄz‚±º‚ÅΩÀ¢‚Åæ for s = 1,‚Ä¶,d, i,j = 1,‚Ä¶,t,
    # 
    # and 
    #
    #   z·µ¢‚ÅΩÀ¢‚Åæ·µÄx‚±º‚ÅΩÀ¢‚Åæ for s = 1,‚Ä¶,d, i,j = 1,‚Ä¶,t,
    #
    # respcetively

    Z_inner = [ zeros(rank, rank) for _ in 1:d ]
    ZX      = [ zeros(rank, rank) for _ in 1:d ]

    for s in 1:d

        BLAS.syrk!('L', 'T', 1.0, Z[s], 1.0,  Z_inner[s])      # Compute only lower triangle
        BLAS.gemm!('T', 'N', 1.0, Z[s], x.fmat[s], 1.0, ZX[s]) 

    end

    result = 0.0

    mask_s = trues(d)
    mask_r = trues(d)

    # We can separate the large sum 
    #
    #   Œ£‚ÇõŒ£·µ£Œ£·µ¢Œ£‚±º x·µ¢‚ÅΩ¬π‚Åæ·µÄx‚±º‚ÅΩ¬π‚Åæ ‚ãØ z·µ¢‚ÅΩÀ¢‚Åæ·µÄx‚±º‚ÅΩÀ¢‚Åæ ‚ãØ x·µ¢‚ÅΩ ≥‚Åæ·µÄz‚±º‚ÅΩ ≥‚Åæ ‚ãØ x·µ¢‚ÅΩ·µà‚Åæ·µÄx‚±º‚ÅΩ·µà‚Åæ
    #
    # into the cases 
    #
    #   (1) s  = r, i  = j,
    #   (2) s != r, i  = j,
    #   (3) s  = r, i != j,
    #   (4) s != r, i != j
    #
    # and simplify the calculation using the fact that some inner products 
    # appear twice (only access lower triangle of matrices) and that the norm
    # of the columns of the factor matrices are one.

    for s in 1:d

        for j = 1:rank

            result += Œõ[j, j] * Z_inner[s][j, j]

            mask_s[s] = false

            for i = skipindex(j, j:rank)

                result += 2 * Œõ[i, j] * maskprod(X_inner[mask_s], i, j) * Z_inner[.!mask_s][1][i, j]

            end

        end

        for r = skipindex(s, 1:d)

            mask_r[r] = false

            for i = 1:rank

                result += Œõ[i, i] * ZX[s][i, i] * ZX[r][i, i]

                for j = skipindex(i, 1:rank)

                    result += Œõ[j, i] * maskprod(ZX[mask_s .&& mask_r], i, j) * maskprod(ZX[.!(mask_s .&& mask_r)], j, i)

                end

            end

            mask_r[r] = true
        end

        mask_s[s] = true

    end

    return result

end


function compressed_residual(
        Ly::Vector{LowerTriangle{T}},
        Œõ::LowerTriangle{T},
        H::KroneckerMatrix{T},
        y::ktensor,
        b::Vector{Array{T}}) where T <:AbstractFloat

    # TODO: 
    #
    # We know that 
    #
    # ||Hy - b||¬≤ = ||Hy||¬≤ -2‚ãÖb·µÄ(Hy) + ||b||¬≤ 
    
    d = length(H)
    t = ncomponents(y)

    # For this we evaluate all Z‚ÅΩÀ¢‚Åæ[:, i] = H‚Çõy‚ÅΩÀ¢‚Åæ·µ¢ ‚àà ‚Ñù‚Åø‚Çõ for i = 1,‚Ä¶,t
    Z = matrix_vector(H, y)

    # First we compute ||Hy||¬≤
    Hy_norm = efficient_matrix_vector_norm(y, Œõ, Ly, Z)

    # Now we compute <Hy, b>‚ÇÇ
    bY = [ zeros(t) for _ in 1:d ] # b‚Çõ·µÄy·µ¢‚ÅΩÀ¢‚Åæ
    bZ = [ zeros(t) for _ in 1:d ] # b‚Çõ·µÄz·µ¢‚ÅΩÀ¢‚Åæ, where z·µ¢‚ÅΩÀ¢‚Åæ = H‚Çõ‚ãÖy·µ¢‚ÅΩÀ¢‚Åæ

    Hy_b = innerprod_kronsum_tensor!(bY, bZ, Z, y, b)

    # Finally we compute the 2-norm of b
    b_norm = prod( norm(b[s]) for s in 1:d )

    return Hy_norm - 2 * Hy_b + b_norm
    
end

function squared_tensor_entries(
        Y_masked::Vector{LowerTriangle{T}},
        Œì::LowerTriangle{T}) where T <: AbstractFloat

    # Compute Œ£ |y_ùîè|¬≤ with formula in paper, when y is given in CP format:
    #
    #   Œ£ |y_ùîè|¬≤ = ||Œ£·µ¢ e‚Çñ‚Çõ·µÄ y·µ¢‚ÅΩÀ¢‚Åæ ‚®Ç ‚±º‚â† ‚Çõ y·µ¢‚ÅΩ ≤‚Åæ||¬≤, 
    #
    # where Œ¥ represents the vector holding k‚Çõ-th entry of each column of the 
    # s-th factor matrix of y.
    
    t = size(Y_masked, 1)

    value = 0.0

    for k = 1:t

        value += Œì[k, k] 

        for i = skipindex(k, k:t)

            value += 2 * Œì[i, k] * maskprod(Y_masked, i, k) # Symmetry

        end
    end

    return value 
end

    
function residual_norm(H::KronMat{T}, y::ktensor, ùîé::Vector{Int}, b) where T<:AbstractFloat
    
    # Compute norm of the residual according to Lemma 3.4 of paper.
    
    # Œ£ |hÀ¢‚Çñ‚Çä‚ÇÅ‚Çñ|¬≤ * Œ£ |y\_ùîè|¬≤ + ||‚Ñãy - bÃÉ||¬≤
    
    # Get entries at indices (k‚Çõ+1, k‚Çõ) for each dimension with pair of 
    # multiindices ùîé+1, ùîé

    d = length(H) # Number of dimensions

    t = ncomponents(y) # Tensor rank

    # Allocate memory for (lower triangular) matrices representing inner products
    Ly = [ zeros(t, t) for _ in 1:d ]

    for s = 1:d

        BLAS.syrk!('L', 'T', 1.0, y.fmat[s], 1.0, Ly[s]) # Only need lower triangle

    end

    # Allocate memory for (lower triangular) matrix representing outer product
    # of coefficients.
    
    Œõ = LowerTriangular(zeros(t, t))

    Œõ = compute_lower_triangle!(Œõ, y.lambda)

    res_norm = 0.0

    mask = trues(d)

    for s = 1:d

        Œì = compute_coefficients(Œõ, y.fmat[s][ùîé[s], :])

        mask[s] = false

        y¬≤ = squared_tensor_entries(Ly[mask], Œì)

        res_norm += abs( H[ùîé[s] + 1, ùîé[s]] )^2 * y¬≤

        mask[s] = true

    end

    # Compute squared compressed residual norm
    r‚Çï = compressed_residual(Ly, Symmetric(Œõ, :L), H, y, b)

    return res_norm + r‚Çï

end

function tensor_krylov(A::KronMat{T}, b::KronProd{T}, tol::T, nmax::Int) where T <: AbstractFloat

	# Initilialize implicit tensorized Krylov subspace basis and upper Hessenberg 
	# matrix of compressed linear system
	decompositions = [Arnoldi(A[s], size(A[s], 1)) for s = 1:length(A)]

	# Compute basis and Hessenberg factor of each Krylov subspace ùìö‚Çñ(A‚Çõ, b‚Çõ) 
	for s = 1:length(A)
		
		arnoldi_modified!(A[s], b[s], tol, nmax, decompositions[s])
		
	end


    #H = KroneckerMatrix(decompositions)

    residual_norm(H, y, ùîé)

    
    #y = solve_compressed_system()

	return decompositions
end
