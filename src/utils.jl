using PyCall

tensor_train = pyimport("scikit_tt.tensor_train")
TT           = pytype_query(tensor_train.TT)
TT_solvers   = pyimport("scikit_tt.solvers.sle")

struct CompressedNormBreakdown{T} <: Exception 
    
    r_comp::T

end


Base.showerror(io::IO, e::CompressedNormBreakdown{T}) where T = print(io, e.r_comp, " is strictly negative.")

#function initialize_cores(d::Int, m::Int, n::Int, r1::Int, r2::Int)
#
#    first_core   = zeros(1,  m, n, r2)
#    middle_cores = [ zeros(r1, m, n, r2) for _ in 1:d - 2 ]
#    final_core   = zeros(r1, m, n, 1)
#    cores        = collect( (first_core, middle_cores..., final_core) )
#
#    return cores 
#
#end
#
#function initializeTToperator(A‚Çõ::AbstractMatrix{T}, d::Int) where T
#
#    n = size(A‚Çõ, 1)
#
#    cores = initialize_cores(d, n, n, 2, 2)
#
#    cores[1][1, :, :, 1] = A‚Çõ
#    cores[1][1, :, :, 2] = I(n)
#
#    for s in 2:d-1
#        
#        cores[s][1,:, :, 1] = I(n)
#        cores[s][2,:, :, 1] = A‚Çõ
#        cores[s][2,:, :, 2] = I(n)
#
#    end
#
#    cores[end][1, :, :, 1] = I(n)
#    cores[end][2, :, :, 1] = A‚Çõ
#
#    return TT(cores)
#
#end
#
#function initialize_rhs(b::KronProd{T}, d::Int) where T
#
#    
#    cores = [ zeros(1, size(b[s], 1), 1, 1) for s in 1:d ]
#
#    for s in 1:d
#
#        cores[s][1, :, 1, 1] = b[s]
#
#    end
#
#    return TT(cores)
#
#end
#
#function canonicaltoTT(x::ktensor)
#
#    d     = ndims(x)
#    rank  = ncomponents(x)
#    n     = size(x, 1)
#    cores = initialize_cores(d, n, 1, rank, rank) 
#
#    tmp = redistribute(x, 1) # Redistribute weights
#    
#
#    for i in 1:rank
#
#        #cores[1][1, :, 1, i] = x.lambda[i] .* @view(x.fmat[1][:, i]) # Fill first core
#        #cores[1][1, :, 1, i] = @view(x.fmat[1][:, i]) # Fill first core
#        cores[1][1, :, 1, i] = @view(tmp.fmat[1][:, i]) # Fill first core
#
#    end
#
#    for s in 2:d-1, i in 1:rank
#
#        #cores[s][i, :, 1, i] = x.lambda[i] * @view(x.fmat[s][:, i]) # Fill middle cores
#        #cores[s][i, :, 1, i] = @view(x.fmat[s][:, i]) # Fill middle cores
#        cores[s][i, :, 1, i] = @view(tmp.fmat[s][:, i]) # Fill middle cores
#
#    end
#
#    for i in 1:rank
#
#        #cores[end][i, :, 1, 1] = x.lambda[i] * @view(x.fmat[end][:, i])
#        #cores[end][i, :, 1, 1] = @view(x.fmat[end][:, i])
#        cores[end][i, :, 1, 1] = @view(tmp.fmat[end][:, i])
#
#    end
#
#    return TT(cores)
#
#end
#
#function TTcompressedresidual(H::KronMat{T}, y::ktensor, b::KronProd{T}) where T
#
#    py"""
#
#    import scikit_tt.tensor_train as tensor_train
#
#    """
#
#    TT = py"tensor_train".TT
#
#    d = length(H)
#
#    H_TT = TT(initializeTToperator(H.ùñ≥[1], d))
#    y_TT = TT(canonicaltoTT(y))
#    b_TT = TT(initialize_rhs(b, d))
#
#    TT_multiplication = py"tensor_train.TT.__matmul__"
#    TT_subtraction    = py"tensor_train.TT.__sub__"
#    TT_norm           = py"tensor_train.TT.norm"
#
#    product    = TT_multiplication(H_TT, y_TT)
#    difference = TT_subtraction(product, b_TT)
#
#    return TT_norm(difference)^2
#end



function compute_lower_outer!(L::AbstractMatrix{T}, Œ≥::Array{T}) where T 

    # Lower triangular matrix representing the outer product of a vector with itself

    t = size(L, 1)

    for j = 1:t, i = j:t

        L[i, j] = Œ≥[i] * Œ≥[j]

    end

end

function cp_tensor_coefficients(Œõ::LowerTriangle{T}, Œ¥::Array{T}) where T 

    # Given a collection of lower triangular matrices containing all values of 
    # Œª‚ÅΩÀ¢‚Åæcorresponding to each factor matrix in the CP-decomposition of the 
    # tensor y, and an array Œ¥ containing the k-th entry of a column of said 
    # factor matrices, compute the product of both (see section 3.3. bottom).

    t = length(Œ¥)

    Œî = ones(t, t)

    # Lower triangle of outer product
    compute_lower_outer!(Œî, Œ¥) # ‚àà ‚Ñù·µó·µó

    Œì = Œî .* Œõ

    return Œì

end

function skipindex(index::Int, range::UnitRange{Int})

    return Iterators.filter(r -> r != index, range)

end

function maskprod(A::KronStruct{T}, i::Int, j::Int) where T 

    # Compute product of entries (i,j) of the matrices contained in A.

    return prod(getindex.(A, i, j)) 

end


function maskprod(x::AbstractVector{<:AbstractVector{T}}, i::Int) where T

    return prod(getindex.(x, i))

end

function maskprod(x::FMatrices{T}, i::Int) where T 

    return prod(getindex.(x, 1, i)) 

end

function compute_lower_triangles!(LowerTriangles::FMatrices{T}, x::ktensor) where T

    for s = 1:length(LowerTriangles)

        BLAS.syrk!('L', 'T', 1.0, x.fmat[s], 1.0, LowerTriangles[s])

    end

end

function squared_tensor_entries(Y_masked::FMatrices{T}, Œì::AbstractMatrix{T}) where T 

    # Compute Œ£ |y_ùîè|¬≤ with formula in paper, when y is given in CP format:
    #
    #   Œ£ |y_ùîè|¬≤ = ||Œ£·µ¢ e‚Çñ‚Çõ·µÄ y·µ¢‚ÅΩÀ¢‚Åæ ‚®Ç ‚±º‚â† ‚Çõ y·µ¢‚ÅΩ ≤‚Åæ||¬≤, 
    #
    # where Œ¥ represents the vector holding k‚Çõ-th entry of each column of the 
    # s-th factor matrix of y.
    #
    # We use the symmetry of the inner products and only require to iterate in
    # the correct way:
    #
    # 2 ‚ãÖŒ£‚Çñ‚Çå‚ÇÅ Œ£·µ¢‚Çå‚Çñ‚Çä‚ÇÅ Œì[i, k] ‚ãÖ Œ†‚±º‚â† ‚Çõ<y·µ¢‚ÅΩ ≤‚Åæ,y‚Çñ‚ÅΩ ≤‚Åæ> + Œ£·µ¢‚Çå‚ÇÅ Œ†‚±º‚â† ‚Çõ||y·µ¢‚ÅΩ ≤‚Åæ||¬≤
    
    t = size(Œì, 1)

    value = 0.0

    for k = 1:t, i = 1:t

        value += Œì[i, k] * maskprod(Y_masked, i, k)

    end

    return value 
end


function matrix_vector(A::KronMat, x::ktensor)

    # Compute the matrix vector products 
    #   
    #   z‚ÅΩÀ¢‚Åæ·µ¢ = A‚Çõ‚ãÖ x‚ÅΩÀ¢‚Åæ·µ¢ for s = 1,‚Ä¶,d, i = 1,‚Ä¶,t
    #
    # This is equivalent as computing the product Z‚ÅΩÀ¢‚Åæ = A‚Çõ‚ãÖX‚ÅΩÀ¢‚Åæ, where X‚ÅΩÀ¢‚Åæ
    # are the factor matrices of the CP-tensor x.

    length(A) == ndims(x) || throw(DimensionMismatch("Kronecker matrix and vector (Kruskal tensor) have different number of components"))

    orders = [ size(A[s], 1) for s in 1:length(A) ]
    rank   = ncomponents(x)

    # Return vector of matrices as described above
    Z = [ zeros(orders[s], rank) for s in eachindex(A) ]

    for s = 1:length(A)

        LinearAlgebra.mul!(Z[s], A[s], x.fmat[s])

    end

    return Z

end

function mask_matrix_collection(
    YZ    ::FMatrices{T},
    mask_s::BitVector, mask_r::BitVector, 
    i     ::Int, j::Int) where T

    mask = mask_s .‚äª mask_r
    
    return !any(mask) ? 1.0 : maskprod(YZ[mask_s], i, j) * maskprod(YZ[mask_r], j, i)

end

function evalmvnorm(
    Œõ      ::AbstractMatrix{T},
    Y      ::FMatrices{T},
    YZ     ::FMatrices{T},
    Z_inner::FMatrices{T},
    i::Int, j::Int, 
    mask_s, mask_r) where T

    Œ±  = maskprod(Y[.!(mask_s .|| mask_r)], i, j)
    Œ≤ = mask_matrix_collection(YZ, mask_s, mask_r, i, j)
    Œ≥ = maskprod(Z_inner[mask_s .&& mask_r], i, j)

    return Œõ[i, j] * Œ± * Œ≤ * Œ≥

end


function MVnorm(x::ktensor, Œõ::AbstractMatrix{T}, lowerX::FMatrices{T}, Z::FMatrices{T}) where T

    Œõ_complete = Symmetric(Œõ, :L)
    X          = Symmetric.(lowerX, :L)
    Z_inner    = [ Z[s]'Z[s]      for s in 1:length(Z)]
    XZ         = [ x.fmat[s]'Z[s] for s in 1:ndims(x) ]

    d    = length(lowerX)
    rank = length(x.lambda)

    mask_s = falses(d)
    mask_r = falses(d)

    MVnorm = 0.0

    for j = 1:rank, i = 1:rank

        for s in 1:d, r in 1:d

            mask_s[s] = true

            mask_r[r] = true

            MVnorm += evalmvnorm(Œõ_complete, X, XZ, Z_inner, i, j, mask_s, mask_r)

            mask_r[r] = false

            mask_s[s] = false

        end

    end

    @assert MVnorm >= 0.0

    return MVnorm
    
end

function evalinnerprod(y::ktensor, bY::KronProd{T}, bZ::KronProd{T}, i::Int, mask::BitVector) where T

    return y.lambda[i] * maskprod(bZ[mask], i) * maskprod(bY[.!mask], i)

end

function tensorinnerprod(Ax::FMatrices{T}, x::ktensor, y::KronProd{T}) where T

    d   = ndims(x)
    t   = ncomponents(x)

    yX  = [ zeros(t) for _ in 1:d ]
    yAx = [ zeros(t) for _ in 1:d ]

    for s in 1:d

        yX[s]  = BLAS.gemv!('T', 1.0, x.fmat[s], y[s], 0.0,  yX[s])
        yAx[s] = BLAS.gemv!('T', 1.0, Ax[s],     y[s], 0.0, yAx[s])

    end

    Ax_y = 0.0

    mask = falses(d)
    
    for s in 1:d

        mask[s] = true

        for i in 1:ncomponents(x)

            Ax_y += evalinnerprod(x, yX, yAx, i, mask)

        end

        mask[s] = false
    end

    @assert Ax_y >= 0.0

    return Ax_y

end

function compressed_residual(
    Ly::FMatrices{T},
    Œõ ::AbstractMatrix{T},
    H ::KronMat,
    y ::ktensor,
    b ::KronProd{T}) where T 

    # We know that 
    
    #   ||Hy - b||¬≤ = ||Hy||¬≤ -2‚ãÖb·µÄ(Hy) + ||b||¬≤ 

    # For this we evaluate all z‚ÅΩÀ¢‚Åæ·µ¢=  Z‚ÅΩÀ¢‚Åæ[:, i] = H‚Çõy‚ÅΩÀ¢‚Åæ·µ¢ ‚àà ‚Ñù·µè‚Çõ for i = 1,‚Ä¶,t
    Z  = matrix_vector(H, y)
    Ly = Symmetric.(Ly, :L)

    Hy_norm = MVnorm(y, Symmetric(Œõ, :L), Ly, Z) # First we compute ||Hy||¬≤
    Hy_b    = tensorinnerprod(Z, y, b)           # <Hy, b>‚ÇÇ
    b_norm  = kronproddot(b)                     # squared 2-norm of b
    r_comp  = Hy_norm - 2* Hy_b + b_norm

    r_comp < 0.0 ? throw( CompressedNormBreakdown{T}(r_comp) ) : return r_comp

    return r_comp

end


function residual_norm!(
    H                  ::KronMat,
    y                  ::ktensor,
    ùîé                  ::Vector{Int},
    subdiagonal_entries::Vector{T},
    b                  ::KronProd{T}) where T
    
    # Compute squared norm of the residual according to Lemma 3.4 of paper.
    
    # Œ£ |hÀ¢‚Çñ‚Çä‚ÇÅ‚Çñ|¬≤ * Œ£ |y\_ùîè|¬≤ + ||‚Ñãy - bÃÉ||¬≤
    
    # Get entries at indices (k‚Çõ+1, k‚Çõ) for each dimension with pair of 
    # multiindices ùîé+1, ùîé

    d  = length(H)                    # Number of dimensions
    t  = ncomponents(y)               # Tensor rank
    Ly = [ zeros(t, t) for _ in 1:d ] # Allocate memory for matrices representing inner products
    Œõ  = LowerTriangular(zeros(t, t)) # Allocate memory for matrix representing outer product of coefficients.

    compute_lower_triangles!(Ly, y)
    compute_lower_outer!(Œõ, y.lambda)

    Ly       = Symmetric.(Ly, :L) # Symmetrize (momentarily abandon the use of symmetry)
    res_norm = 0.0
    mask     = trues(d)

    for s = 1:d

        Œì = Symmetric(cp_tensor_coefficients(Œõ, y.fmat[s][ùîé[s], :]), :L) # Symmetric matrix 

        mask[s]   = false
        y¬≤        = squared_tensor_entries(Ly[mask], Œì)
        res_norm += abs2( subdiagonal_entries[s] ) * y¬≤
        mask[s]   = true

    end

    r_comp = compressed_residual(Ly, Œõ, H, y, b) # Compute squared compressed residual norm

    return r_comp, sqrt(res_norm + r_comp)

end


function normalize!(rhs::KronProd{T}) where T

    for i in 1:length(rhs)

        rhs[i] *= inv(LinearAlgebra.norm(rhs[i]))

    end

end

function initialize_compressed_rhs(b::KronProd, V::KronMat) 

        bÃÉ        = [ zeros( size(b[s]) )  for s in eachindex(b) ]
        b_minors = principal_minors(bÃÉ, 1)
        columns  = kth_columns(V, 1)
        update_rhs!(b_minors, columns, b, 1)

        return bÃÉ
end

function update_rhs!(bÃÉ::KronProd{T}, V::KronProd{T}, b::KronProd{T}, k::Int) where T
    # bÃÉ = V·µÄb = ‚®Ç V‚Çõ·µÄ ‚ãÖ ‚®Ç b‚Çõ = ‚®Ç V‚Çõ·µÄb‚Çõ
    
    for s in eachindex(bÃÉ)

        # Update one entry of each component of bÃÉ by performing a single inner product 
        bÃÉ[s][k] = dot(V[s], b[s])

    end

end

function basis_tensor_mul!(x::ktensor, V::KronMat, y::ktensor) 

    x.lambda = copy(y.lambda)

    for s in eachindex(V)

        LinearAlgebra.mul!(x.fmat[s], V[s], y.fmat[s])

    end

end

function compute_minors(tensor_decomp::TensorDecomposition{T}, rhs::KronProd{T}, n::Int, k::Int) where T

        H_minors = principal_minors(tensor_decomp.H, k)
        V_minors = principal_minors(tensor_decomp.V, n, k)
        b_minors = principal_minors(rhs, k)

        return H_minors, V_minors, b_minors
    
end


function matrix_exponential_vector!(
    y::ktensor,
    A::KronMat{T, U},
    b::KronProd{T},
    Œ≥::T, 
    k::Int) where {T, U<:Instance}

    tmp = first(A)

    expA = exp(Œ≥ * tmp)

    for s = 1:length(A)

        y.fmat[s][:, k] =  expA * b[s] # Update kth column

    end

end


function exponentiate(A::AbstractMatrix{T}, Œ≥::T) where T

    tmp    = zeros(size(A))
    result = zeros(size(A))

    Œª, V = LinearAlgebra.eigen(A)

    Œõ = Diagonal(exp.(Œ≥ .* Œª))

    LinearAlgebra.mul!(tmp, V, Œõ)

    LinearAlgebra.mul!(result, tmp, transpose(V))

    return result

end
