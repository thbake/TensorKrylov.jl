using TensorKrylov: compute_lower_outer!, maskprod, compressed_residual, residual_norm
using Kronecker, TensorToolbox, LinearAlgebra, BenchmarkTools, SparseArrays


# Everything here works
#@testset "Lower triangle computations" begin
#
#    d = 4
#
#    t = 5
#
#    A = rand(t, t)
#
#    Œª = rand(t)
#
#    Œõ = LowerTriangular(Œª * Œª')
#
#    M = LowerTriangular(zeros(t, t))
#
#    compute_lower_outer!(M, Œª)
#
#    @test M ‚âà Œõ atol = 1e-15
#end
#
#@testset "Masked products" begin
#
#    n = 5
#    d = 4
#
#    matrices = [ rand(n, n) for _ in 1:d ]
#
#    values      = ones(n, n)
#    test_values = ones(n, n)
#
#    for j = 1:n, i = 1:n
#        
#        values[i, j] = maskprod(matrices, i, j) 
#
#    end
#
#    for s = 1:d
#
#        for j = 1:n, i = 1:n
#
#            test_values[i, j] *= matrices[s][i, j]
#
#        end
#
#    end
#
#    @test all(values .== test_values)
#
#    vec_matrix = [ rand(n, n) ]
#
#    for j = 1:n, i = 1:n
#
#        values[i, j] = maskprod(vec_matrix, i, j)
#
#    end
#
#    test_values .= copy(vec_matrix...)
#
#    @test all(values .== test_values)
#
#end
#
#@testset "(Compressed) residual norm computations" begin
#    
#    # We consider tensors of order 4, where each mode is 4 as well.
#    d = 5
#    n‚Çõ= 5
#
#    H·µ¢= rand(n‚Çõ, n‚Çõ)
#
#    # Make sure matrix is not singular
#    H = KroneckerMatrix{Float64}([H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢])
#
#    # Matrix given as Kronecker sum
#    H_kronsum = kroneckersum( H.ùñ≥... )
#    
#    u = rand(n‚Çõ)
#    v = rand(n‚Çõ)
#    w = rand(n‚Çõ)
#    x = rand(n‚Çõ)
#    z = rand(n‚Çõ)
#
#    # In the following we construct b as a rank 1 tensor such that the solution
#    # of the linear system H * y = b has a good low rank approximation.
#    b = zeros(n‚Çõ, n‚Çõ, n‚Çõ, n‚Çõ, n‚Çõ)
#
#    for m = 1:n‚Çõ, l = 1:n‚Çõ, k = 1:n‚Çõ, j = 1:n‚Çõ, i = 1:n‚Çõ
#
#        b[i, j, k, l, m] = u[i] * v[j] * w[k] * x[l] * z[m]
#
#    end
#
#    N = n‚Çõ^d  
#
#    rank = 3
#
#    # Create Kruskal tensor such that there is no difference between this and its
#    # full tensor representation
#    y = ktensor( ones(rank), [ rand(d, rank) for _ in 1:d] )
#
#    Y_vec = reshape(full(y), N)
#
#    normalize!(y)
#
#    @info "Norm difference:" norm(reshape(full(y), N) - Y_vec)
#
#    # First test ||Hy||¬≤
#    # Allocate memory for (lower triangular) matrices representing inner products
#    Y_inner = [ zeros(rank, rank) for _ in 1:d ]
#
#    for s = 1:d
#
#        LinearAlgebra.BLAS.syrk!('L', 'T', 1.0, y.fmat[s], 1.0, Y_inner[s])
#
#    end
#
#    Z = matrix_vector(H, y)
#
#    Œõ = y.lambda * y.lambda'
#
#    Ly = [LowerTriangular( zeros(rank, rank) ) for _ in 1:d]
#
#    map!(LowerTriangular, Ly, Y_inner)
#
#    # Compute squared norm of Kronecker matrix and ktensor ||Hy||¬≤
#    efficient_norm      = efficient_matrix_vector_norm(y, Œõ, Ly, Z)
#    exact_matrix_vector = dot( (H_kronsum * Y_vec),  (H_kronsum * Y_vec) )
#
#    bY = [ zeros(1, rank) for _ in 1:d ] # b‚Çõ·µÄy·µ¢‚ÅΩÀ¢‚Åæ
#    bZ = [ zeros(1, rank) for _ in 1:d ] # b‚Çõ·µÄz·µ¢‚ÅΩÀ¢‚Åæ, where z·µ¢‚ÅΩÀ¢‚Åæ = H‚Çõ‚ãÖy·µ¢‚ÅΩÀ¢‚Åæ
#
#    # Right-hand side represented as factors of Kronecker product
#    b_kronprod = [u, v, w, x, z]
#
#    # Vectorization of right-hand side
#    b_vec = reshape(b, N)
#
#    # Compute inner product of Kronecker matrix times ktensor and right-hand side <Hy, b>
#    innerprod        = innerprod_kronsum_tensor!(bY, bZ, Z, y, b_kronprod)
#    exact_innerprod  = dot(H_kronsum * Y_vec, b_vec)
#
#    @test efficient_norm ‚âà exact_matrix_vector 
#    @test innerprod      ‚âà dot(H_kronsum * Y_vec, b_vec) atol = 1e-12 
#
#    # Compressed residual norm
#    r_comp = compressed_residual(Ly, LowerTriangular(Œõ), H, y, b_kronprod)
#
#    exact_comp_norm = exact_matrix_vector - 2 * dot(H_kronsum * Y_vec, b_vec) + dot(b_vec, b_vec)
#    
#    @info exact_comp_norm
#    @test r_comp ‚âà exact_comp_norm 
#
#
#    res_norm = residual_norm(H, y, [3, 3, 3, 3, 3], b_kronprod)
#
#    @info abs(res_norm - exact_comp_norm)
#
#    @info cond(H_kronsum)
#
#
#    #@info "Exact ||Hy||¬≤: " exact_matrix_vector " exact 2 ‚ãÖ<Hy, b>: " 2*dot(H_kronsum*Y_vec, b_vec) " exact ||b||¬≤: " dot(b_vec, b_vec)
#    
#    # On the order of the machine precision
#
#    # Check that we have indeed constructed a "good" low-rank approximation
#    #@test norm(full(y) - Y) < 1e-13
#
#end

@testset "Analytic results" begin

    d = 2

    n‚Çõ = 10


    h = inv(n‚Çõ + 1)

    A‚Çõ= sparse(

            Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) )
        )

    #A‚Çõ= sparse( Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) ) )

    #A = KroneckerMatrix{Float64}([A‚Çõ for _ in 1:d])
    A = trikronmat([n‚Çõ for _ in 1:d])

    b = [ rand(n‚Çõ) for _ in 1:d ]

    œÑ = 1e-14

    #Œª_min = (2 / h^2) * (1 - cos( œÄ / (n‚Çõ + 1)))
    #Œª_max = (2 / h^2) * (1 - cos( n‚Çõ * œÄ / (n‚Çõ + 1)))

    Œª_min = d * 2(1 - cos( œÄ / (n‚Çõ + 1)))
    Œª_max = d * 2(1 - cos( n‚Çõ * œÄ / (n‚Çõ + 1)))

    A_big = kroneckersum(A.ùñ≥...)

    julia_eigenvalues = eigvals(A_big)

    @test Œª_min ‚âà julia_eigenvalues[1]
    @test Œª_max ‚âà julia_eigenvalues[end]

    #Œ∫ = 4 * (n‚Çõ + 1)^2 / (œÄ^2 * d)
    #Œ∫ = 1 + cos(œÄ / (n‚Çõ + 1)) * inv( d * (1 - cos(œÄ / (n‚Çõ + 1)) ))

    Œ∫ = Œª_max / Œª_min

    @test Œ∫ ‚âà cond(A_big)

    @assert issparse(A_big)

end

@testset "Solution of compressed system" begin

    d = 10

    n‚Çõ = 200

    nmax = 170

    h = inv(n‚Çõ + 1)

    A‚Çõ= sparse(inv(h^2) * Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) ))
    #A‚Çõ= sparse( Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) ) )

    A = KroneckerMatrix{Float64}([A‚Çõ for _ in 1:d])

    b = [ rand(n‚Çõ) for _ in 1:d ]
    
    for s in eachindex(b)

        b[s] = inv(LinearAlgebra.norm(b[s])) .* b[s]

    end

    #@info "b" b

    b_norm = kronprodnorm(b)

    @info "Norm of ‚®Ç b " b_norm

    x = tensor_krylov(A, b, 1e-9, nmax, TensorLanczos{Float64})

end


