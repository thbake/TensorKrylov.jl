using TensorKrylov: compute_lower_outer!, maskprod, compressed_residual, residual_norm, TensorDecomposition, kth_columns
using Kronecker, TensorToolbox, LinearAlgebra, BenchmarkTools, SparseArrays, ProfileView


# Everything here works
#@testset "Lower triangle computations" begin
#
#    d = 4
#
#    t = 5
#
#    A = rand(t, t)
#
#    Œª = rand(t)
#
#    Œõ = LowerTriangular(Œª * Œª')
#
#    M = LowerTriangular(zeros(t, t))
#
#    compute_lower_outer!(M, Œª)
#
#    @test M ‚âà Œõ atol = 1e-15
#end
#
#@testset "Masked products" begin
#
#    n = 5
#    d = 4
#
#    matrices = [ rand(n, n) for _ in 1:d ]
#
#    values      = ones(n, n)
#    test_values = ones(n, n)
#
#    for j = 1:n, i = 1:n
#        
#        values[i, j] = maskprod(matrices, i, j) 
#
#    end
#
#    for s = 1:d
#
#        for j = 1:n, i = 1:n
#
#            test_values[i, j] *= matrices[s][i, j]
#
#        end
#
#    end
#
#    @test all(values .== test_values)
#
#    vec_matrix = [ rand(n, n) ]
#
#    for j = 1:n, i = 1:n
#
#        values[i, j] = maskprod(vec_matrix, i, j)
#
#    end
#
#    test_values .= copy(vec_matrix...)
#
#    @test all(values .== test_values)
#
#end
#
#@testset "(Compressed) residual norm computations" begin
#    
#    # We consider tensors of order 4, where each mode is 4 as well.
#    d = 5
#    n‚Çõ= 5
#
#    H·µ¢= rand(n‚Çõ, n‚Çõ)
#
#    # Make sure matrix is not singular
#    H = KroneckerMatrix{Float64}([H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢, H·µ¢'H·µ¢])
#
#    # Matrix given as Kronecker sum
#    H_kronsum = kroneckersum( H.ùñ≥... )
#    
#    u = rand(n‚Çõ)
#    v = rand(n‚Çõ)
#    w = rand(n‚Çõ)
#    x = rand(n‚Çõ)
#    z = rand(n‚Çõ)
#
#    # In the following we construct b as a rank 1 tensor such that the solution
#    # of the linear system H * y = b has a good low rank approximation.
#    b = zeros(n‚Çõ, n‚Çõ, n‚Çõ, n‚Çõ, n‚Çõ)
#
#    for m = 1:n‚Çõ, l = 1:n‚Çõ, k = 1:n‚Çõ, j = 1:n‚Çõ, i = 1:n‚Çõ
#
#        b[i, j, k, l, m] = u[i] * v[j] * w[k] * x[l] * z[m]
#
#    end
#
#    N = n‚Çõ^d  
#
#    rank = 3
#
#    # Create Kruskal tensor such that there is no difference between this and its
#    # full tensor representation
#    y = ktensor( ones(rank), [ rand(d, rank) for _ in 1:d] )
#
#    Y_vec = reshape(full(y), N)
#
#    normalize!(y)
#
#    @info "Norm difference:" norm(reshape(full(y), N) - Y_vec)
#
#    # First test ||Hy||¬≤
#    # Allocate memory for (lower triangular) matrices representing inner products
#    Y_inner = [ zeros(rank, rank) for _ in 1:d ]
#
#    for s = 1:d
#
#        LinearAlgebra.BLAS.syrk!('L', 'T', 1.0, y.fmat[s], 1.0, Y_inner[s])
#
#    end
#
#    Z = matrix_vector(H, y)
#
#    Œõ = y.lambda * y.lambda'
#
#    Ly = [LowerTriangular( zeros(rank, rank) ) for _ in 1:d]
#
#    map!(LowerTriangular, Ly, Y_inner)
#
#    # Compute squared norm of Kronecker matrix and ktensor ||Hy||¬≤
#    efficient_norm      = efficient_matrix_vector_norm(y, Œõ, Ly, Z)
#    exact_matrix_vector = dot( (H_kronsum * Y_vec),  (H_kronsum * Y_vec) )
#
#    bY = [ zeros(1, rank) for _ in 1:d ] # b‚Çõ·µÄy·µ¢‚ÅΩÀ¢‚Åæ
#    bZ = [ zeros(1, rank) for _ in 1:d ] # b‚Çõ·µÄz·µ¢‚ÅΩÀ¢‚Åæ, where z·µ¢‚ÅΩÀ¢‚Åæ = H‚Çõ‚ãÖy·µ¢‚ÅΩÀ¢‚Åæ
#
#    # Right-hand side represented as factors of Kronecker product
#    b_kronprod = [u, v, w, x, z]
#
#    # Vectorization of right-hand side
#    b_vec = reshape(b, N)
#
#    # Compute inner product of Kronecker matrix times ktensor and right-hand side <Hy, b>
#    innerprod        = innerprod_kronsum_tensor!(bY, bZ, Z, y, b_kronprod)
#    exact_innerprod  = dot(H_kronsum * Y_vec, b_vec)
#
#    @test efficient_norm ‚âà exact_matrix_vector 
#    @test innerprod      ‚âà dot(H_kronsum * Y_vec, b_vec) atol = 1e-12 
#
#    # Compressed residual norm
#    r_comp = compressed_residual(Ly, LowerTriangular(Œõ), H, y, b_kronprod)
#
#    exact_comp_norm = exact_matrix_vector - 2 * dot(H_kronsum * Y_vec, b_vec) + dot(b_vec, b_vec)
#    
#    @info exact_comp_norm
#    @test r_comp ‚âà exact_comp_norm 
#
#
#    res_norm = residual_norm(H, y, [3, 3, 3, 3, 3], b_kronprod)
#
#    @info abs(res_norm - exact_comp_norm)
#
#    @info cond(H_kronsum)
#
#
#    #@info "Exact ||Hy||¬≤: " exact_matrix_vector " exact 2 ‚ãÖ<Hy, b>: " 2*dot(H_kronsum*Y_vec, b_vec) " exact ||b||¬≤: " dot(b_vec, b_vec)
#    
#    # On the order of the machine precision
#
#    # Check that we have indeed constructed a "good" low-rank approximation
#    #@test norm(full(y) - Y) < 1e-13
#
#end

@testset "Residual computations" begin

    function solvecompressed(H::KroneckerMatrix{T}, b::Vector{<:AbstractVector{T}}) where T<:AbstractFloat
    #function solvecompressed(H::KroneckerMatrix{T}, b::Vector{T}) where T<:AbstractFloat

        H_expanded = Symmetric(kroneckersum(H.ùñ≥...))
        #H_expanded = Symmetric(Matrix(H.ùñ≥...))
        b_expanded = kron(b...)
        y          = H_expanded\b_expanded
        #y          = H_expanded\b

        return y

    end

    function exactresidualnorm(A::KroneckerMatrix{T}, b::Vector{<:AbstractVector{T}}, x‚Çñ::AbstractVector{T}) where T<:AbstractFloat
        A_expanded = kroneckersum(A.ùñ≥...)
        #A_expanded = A.ùñ≥[1]
        b_expanded = kron(b...)
        #b_expanded = b[1]
        tmp        = zeros(size(A_expanded, 1))

        mul!(tmp, A_expanded, x‚Çñ)

        r‚Çñ = b_expanded - tmp

        return sqrt(dot(r‚Çñ, r‚Çñ)) * inv(LinearAlgebra.norm(b_expanded))

    end

    function Anormerror(A::AbstractMatrix{T}, x::AbstractVector{T}, x‚Çñ::AbstractVector{T}) where T<: AbstractFloat

        tmp = zeros(size(x)) 
        diff = x - x‚Çñ

        mul!(tmp, A, diff)

        return sqrt(dot(diff, diff))

    end

    function tensor_krylov_exact(
            A::KroneckerMatrix{T},
            b::Vector{<:AbstractVector{T}},
            nmax::Int,
            t_orthonormalization::Type{<:TensorDecomposition}) where T <: AbstractFloat

        d = length(A)
        x‚Çñ = Vector{T}(undef, nentries(A))
        bÃÉ = [ zeros( size(b[s]) )  for s in eachindex(b) ]

        A_expanded = kroneckersum(A.ùñ≥...)
        #A_expanded = A.ùñ≥[1]
        b_expanded = kron(b...)
        #b_expanded = b[1]

        x = Symmetric(A_expanded)\b_expanded

        tensor_decomp      = t_orthonormalization(A)
        orthonormalization = tensor_decomp.orthonormalization

        initial_orthonormalization!(tensor_decomp, b, orthonormalization)
        
        for k = 2:nmax

            orthonormal_basis!(tensor_decomp, k)

            H_minors = principal_minors(tensor_decomp.H, k)
            V_minors = principal_minors(tensor_decomp.V, n, k)
            b_minors = principal_minors(bÃÉ, k)
            #bÃÉ = zeros(k)

            # Update compressed right-hand side bÃÉ = V·µÄb
            update_rhs!(b_minors, V_minors, b, k)
            #bÃÉ = transpose(V) * b_expanded

            y = solvecompressed(H_minors, b_minors)

            mul!(x‚Çñ, kron(V_minors.ùñ≥...), y)
            #mul!(x‚Çñ, V_minors.ùñ≥[1], y)

            r_normexact = exactresidualnorm(A, b, x‚Çñ)

            println(r_normexact)

            error = Anormerror(A_expanded, x, x‚Çñ)

            @info "Error x - x‚Çñ" error

            #residual_norm(H_minors, y)

        end

    end

    d    = 2
    n    = 10
    h    = inv(n + 1)
    T‚Çñ   = inv(h^2) .* (Tridiagonal(-ones(n - 1), 2ones(n), -ones(n - 1)))
    A    = KroneckerMatrix{Float64}([T‚Çñ for _ in 1:d])
    b    = [ rand(n) for _ in 1:d ]
    nmax = 9

    tensor_krylov_exact(A, b, nmax, TensorLanczos{Float64})

end

#@testset "Analytic results" begin
#
#    d = 2
#
#    n‚Çõ = 10
#
#
#    h = inv(n‚Çõ + 1)
#
#    A‚Çõ= sparse(
#
#            Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) )
#        )
#
#    #A‚Çõ= sparse( Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) ) )
#
#    #A = KroneckerMatrix{Float64}([A‚Çõ for _ in 1:d])
#    A = trikronmat([n‚Çõ for _ in 1:d])
#
#    b = [ rand(n‚Çõ) for _ in 1:d ]
#
#    œÑ = 1e-14
#
#    #Œª_min = (2 / h^2) * (1 - cos( œÄ / (n‚Çõ + 1)))
#    #Œª_max = (2 / h^2) * (1 - cos( n‚Çõ * œÄ / (n‚Çõ + 1)))
#
#    Œª_min = d * 2(1 - cos( œÄ / (n‚Çõ + 1)))
#    Œª_max = d * 2(1 - cos( n‚Çõ * œÄ / (n‚Çõ + 1)))
#
#    A_big = kroneckersum(A.ùñ≥...)
#
#    julia_eigenvalues = eigvals(A_big)
#
#    @test Œª_min ‚âà julia_eigenvalues[1]
#    @test Œª_max ‚âà julia_eigenvalues[end]
#
#    #Œ∫ = 4 * (n‚Çõ + 1)^2 / (œÄ^2 * d)
#    #Œ∫ = 1 + cos(œÄ / (n‚Çõ + 1)) * inv( d * (1 - cos(œÄ / (n‚Çõ + 1)) ))
#
#    Œ∫ = Œª_max / Œª_min
#
#    @test Œ∫ ‚âà cond(A_big)
#
#    @assert issparse(A_big)
#
#end

@testset "Symmetric example" begin

    d = 5
    n‚Çõ = 200
    nmax = 190

    h = inv(n‚Çõ + 1)

    A‚Çõ= sparse(inv(h^2) * Tridiagonal( -1ones(n‚Çõ - 1) , 2ones(n‚Çõ), -1ones(n‚Çõ - 1) ))

    A = KroneckerMatrix{Float64}([A‚Çõ for _ in 1:d])

    b = [ rand(n‚Çõ) for _ in 1:d ]
    
    for s in eachindex(b)

        b[s] = inv(LinearAlgebra.norm(b[s])) .* b[s]

    end

    b_norm = kronprodnorm(b)

    @info "Norm of ‚®Ç b " b_norm

    tensor_krylov(A, b, 1e-6, nmax, TensorLanczos{Float64})

end

#@testset "Nonsymmetric example" begin
#
#    d = 5
#    n = 50
#    nmax = 49
#    h = inv(n + 1)
#    c = 10
#
#    L  = sparse( inv(h^2) .* Tridiagonal(-ones(n - 1), 2ones(n), -ones(n - 1)) )
#    A‚Çõ = L + sparse( (c / (4 * h)) .* diagm(-1 => ones(n-1), 0 => 3ones(n), 1 => -5ones(n - 1), 2 => ones(n - 2)) )
#
#    A = KroneckerMatrix{Float64}([A‚Çõ for _ in 1:d])
#
#    b = [ rand(n‚Çõ) for _ in 1:d ]
#    
#    for s in eachindex(b)
#
#        b[s] = inv(LinearAlgebra.norm(b[s])) .* b[s]
#
#    end
#    
#    x = tensor_krylov(A, b, 1e-9, nmax, TensorArnoldi{Float64})
#
#
#    
